{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file call all predicting methods on GEF2012Com and Hvaler\n",
    "Use MeasurePerformance.ipynb file to measure performance of produced prediction\n",
    "**NOTE:** Don't run parallel version of the predict functions, jupyter has trouble with that. Use RunExperiment.R script instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(tidyr)\n",
    "library(dplyr)\n",
    "#library(\"doMC\")\n",
    "source(\"Lib/PredictRandomForest.R\")\n",
    "source(\"Lib/PredictDSHW.R\")\n",
    "source(\"Lib/PredictSemiParametricArima.R\")\n",
    "source(\"Lib/PredictTBATS.R\")\n",
    "source(\"Lib/PredictAverageARIMABaseline.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict for Hvaler\n",
    "HvalerTrainingFile = \"Hvaler/training_set.csv\"\n",
    "HvalerCompleteFile = \"Hvaler/imputed_complete.csv\"\n",
    "OutputDir = \"Hvaler/Predictions/\"\n",
    "HvalerClasses = c('POSIXct', rep(\"numeric\", 21))\n",
    "NCores = 8\n",
    "Zones = paste0(\"subs.\", seq(5, 5))#Only test 1 zone now\n",
    "Temperatures = c(\"T01\")\n",
    "Horizons = seq(1, 24)\n",
    "trainingDf = read.csv(HvalerTrainingFile, stringsAsFactors=FALSE, colClasses=HvalerClasses)\n",
    "completeDf = read.csv(HvalerCompleteFile, stringsAsFactors=FALSE, colClasses=HvalerClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictAverageARIMABaseline(OutputDir, trainingDf, completeDf, Zones, Horizons, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#BE CAREFUL: This will take several hours!\n",
    "predictRandomForest(OutputDir, trainingDf, completeDf, Zones, Temperatures, Horizons, nDataPoints = -1, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This will also take a lot of time\n",
    "predictDSHW(OutputDir, trainingDf, completeDf, Zones, Horizons, modifiedDSHW=FALSE, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This will also take a lot of time\n",
    "predictDSHW(OutputDir, trainingDf, completeDf, Zones, Horizons, modifiedDSHW=TRUE, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This will also take a lot of time\n",
    "predictSemiParametricArima(OutputDir, trainingDf, completeDf, Zones, Temperatures, Horizons, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This will also take a lot of time\n",
    "predictTBATS(OutputDir, trainingDf, completeDf, Zones, Horizons, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Predict for GEFCom2012\n",
    "GEFCom2012TrainingFile = \"GEFCom2012/training_set.csv\"\n",
    "GEFCom2012CompleteFile = \"GEFCom2012/complete.csv\"\n",
    "OutputDir = \"GEFCom2012/Predictions/\"\n",
    "GEFCom2012Classes = c('POSIXct', rep(\"numeric\", 32))\n",
    "Zones = paste0(\"zone.\", seq(14, 14))\n",
    "Temperatures = c(\"T01\",\"T02\",\"T03\",\"T04\",\"T05\",\"T06\",\"T07\",\"T08\",\"T09\",\"T10\",\"T11\")\n",
    "Horizons = seq(1, 24)\n",
    "trainingDf = read.csv(GEFCom2012TrainingFile, stringsAsFactors=FALSE, colClasses=GEFCom2012Classes)\n",
    "completeDf = read.csv(GEFCom2012CompleteFile, stringsAsFactors=FALSE, colClasses=GEFCom2012Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictAverageARIMABaselineParallel(OutputDir, trainingDf, completeDf, Zones, Horizons, plotResult = FALSE, saveResult=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This will take several hours!\n",
    "predictRandomForest(OutputDir, trainingDf, completeDf, Zones, Temperatures, Horizons, nDataPoints = -1, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictDSHW(OutputDir, trainingDf, completeDf, Zones, Horizons, modifiedDSHW=FALSE, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictDSHW(OutputDir, trainingDf, completeDf, Zones, Horizons, modifiedDSHW=TRUE, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictSemiParametricArimaParallel(OutputDir, trainingDf, completeDf, Zones, Temperatures, Horizons, plotResult = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictTBATSParallel(OutputDir, trainingDf, completeDf, Zones, Horizons, plotResult = FALSE, saveResult=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "install.packages(\"bbemkr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "install.packages(\"ranger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"2016-11-27 00:07:14 1311cc8c0fb3-6447: semiParametric|zone.14|period 1|Done in 84.9470386505127\"\n",
      "[1] \"2016-11-27 00:08:32 1311cc8c0fb3-6447: semiParametric|zone.14|period 2|Done in 77.8861882686615\"\n",
      "[1] \"2016-11-27 00:09:38 1311cc8c0fb3-6447: semiParametric|zone.14|period 3|Done in 65.56134557724\"\n",
      "[1] \"2016-11-27 00:11:24 1311cc8c0fb3-6447: semiParametric|zone.14|period 4|Done in 106.720576524734\"\n"
     ]
    }
   ],
   "source": [
    "stopifnot(require('KernSmooth'))\n",
    "    stopifnot(require('bbemkr'))\n",
    "    stopifnot(require('mgcv'))\n",
    "    stopifnot(require('timeDate'))\n",
    "    stopifnot(require(\"MASS\"))\n",
    "    stopifnot(require('forecast'))\n",
    "    stopifnot(require('dplyr'))\n",
    "    stopifnot(require('lubridate'))\n",
    "    stopifnot(require('xts'))\n",
    "    \n",
    "    source(\"Lib/SavePredictions.R\")\n",
    "    #Setup loging file\n",
    "    source(\"Lib/SetupLog.R\")\n",
    "    horizons = Horizons\n",
    "    zones = Zones\n",
    "    temperatures = Temperatures\n",
    "    #Identify where are the start and end of the prediction periods by shifting index of NA\n",
    "    idxNaCases = !complete.cases(trainingDf)\n",
    "    startPoints =  which(idxNaCases & !c(FALSE, head(idxNaCases, -1)) & c(tail(idxNaCases, -1), TRUE))\n",
    "    endPoints = which(idxNaCases & c(TRUE, head(idxNaCases, -1)) & !c(tail(idxNaCases, -1), FALSE))\n",
    "    startDates = trainingDf$DateTime[startPoints]\n",
    "    endDates = trainingDf$DateTime[endPoints]\n",
    "    nTestingPeriods = length(startDates)\n",
    "\n",
    "    #Create Time Features\n",
    "    startYear = year(completeDf$DateTime[1])\n",
    "    endYear = year(tail(completeDf$DateTime, 1))\n",
    "    years = seq(startYear, endYear)\n",
    "    NorwayHolidays = c(EasterMonday(years), \n",
    "                                  Ascension(years), \n",
    "                                  PentecostMonday(years), \n",
    "                                  LaborDay(years), \n",
    "                                  GoodFriday(years), \n",
    "                                  BoxingDay(years), \n",
    "                                  GoodFriday(years)-86400);\n",
    "    completeDf = completeDf %>% mutate(Holiday= isHoliday(as.timeDate(DateTime), NorwayHolidays, wday=0:6)) %>%\n",
    "                                mutate(ChristmasDay= isHoliday(as.timeDate(DateTime), ChristmasDay(years), wday=0:6)) %>%\n",
    "                                mutate(ChristmasEve= isHoliday(as.timeDate(DateTime), ChristmasEve(years), wday=0:6)) %>%\n",
    "                                mutate(NewYearsDay= isHoliday(as.timeDate(DateTime), NewYearsDay(years), wday=0:6)) %>%\n",
    "                                mutate(DoW = factor(wday(DateTime))) %>%\n",
    "                                mutate(ToY = as.numeric(strftime(DateTime, format = \"%j\"))\n",
    "                                            +as.numeric(strftime(DateTime, format=\"%H\"))/24)\n",
    "\n",
    "\n",
    "    #Assume the zone and temperature here\n",
    "    maxHorizon = max(horizons)\n",
    "    predictions = rep(list(trainingDf), maxHorizon);\n",
    "    for (zone in zones){\n",
    "        #Find the best correlated temperature with current zone\n",
    "        maxCor = -1\n",
    "        bestTemp = temperatures[[1]]\n",
    "        for (temp in temperatures){\n",
    "            correlation = cor(completeDf[[zone]], completeDf[[temp]])\n",
    "            if (correlation > maxCor){\n",
    "                maxCor = correlation\n",
    "                bestTemp = temp\n",
    "            }\n",
    "        }\n",
    "        completeDf$T = completeDf[[bestTemp]]\n",
    "        featureDf = completeDf %>% dplyr::select(one_of(c(\"DateTime\", \n",
    "                                            \"Holiday\", \n",
    "                                            \"ChristmasDay\", \n",
    "                                            \"ChristmasEve\", \n",
    "                                            \"NewYearsDay\", \n",
    "                                            \"DoW\", \"ToY\", \"T\", zone )))\n",
    "        featureDf$E = featureDf[[zone]]\n",
    "        featureDf$SmoT = featureDf$T\n",
    "        for (i in 2:length(featureDf$T)){\n",
    "            featureDf$SmoT[i] = 0.15*featureDf$T[i] + 0.85*featureDf$SmoT[i-1]\n",
    "        }\n",
    "\n",
    "        featureDf$LT = rep(0, nrow(featureDf))\n",
    "        featureDf$Residuals = rep(0, nrow(featureDf)) #This is used to train an Arima on residuals\n",
    "        for (period in seq(1, nTestingPeriods)){\n",
    "            startTime = Sys.time()\n",
    "            \n",
    "            #Prepare for training model\n",
    "            startDate = startDates[period]\n",
    "            endDate = endDates[period]\n",
    "            trainData = featureDf %>% filter(DateTime < startDate)\n",
    "            trainData$LT = longTermTrend(trainData$E, trainData$T, trainData$DateTime)\n",
    "\n",
    "            spec = E ~ LT + s(T) + s(SmoT) + s(ToY,bs=\"cc\", k = 100) + \n",
    "                        DoW + ChristmasDay + ChristmasEve + NewYearsDay + Holiday\n",
    "            for (hour in 0:23){ #different model for each hour\n",
    "                #Becareful with logical vector index that not has the same length with dataframe, use which()\n",
    "                trainingIdx = which(hour(trainData$DateTime)==hour) \n",
    "                trainDataAtH = trainData[trainingIdx, ]\n",
    "\n",
    "                model = gam(spec, data=trainDataAtH)\n",
    "                #gam.check(model)\n",
    "\n",
    "                #Testing\n",
    "                testingIdx = which((hour(featureDf$DateTime)==hour) & (featureDf$DateTime >= startDate) & (featureDf$DateTime <= endDate))\n",
    "                featureDf$LT[testingIdx] = rep(tail(trainData$LT, 1), length(testingIdx))\n",
    "                testData = featureDf[testingIdx, ]\n",
    "                prediction = predict(model, testData)\n",
    "                for (h in horizons){ #prediction is the same for all\n",
    "                    predictions[[h]][testingIdx, zone] = prediction\n",
    "                }\n",
    "                featureDf$Residuals[trainingIdx] = model$model$E - model$fitted.values #residuals used for training arima\n",
    "                featureDf$Residuals[testingIdx] = featureDf$E[testingIdx] - prediction #residuals used for testing arima\n",
    "            }\n",
    "            #Run Arima here\n",
    "            startPoint = startPoints[period]\n",
    "            endPoint = endPoints[period]\n",
    "            startTrainingPoint = startPoint - 12*7*24 #Only get 3 month of data for training\n",
    "            xts = xts(featureDf$Residuals, featureDf$DateTime)\n",
    "            trainXts = xts[startTrainingPoint:(startPoint-1)]\n",
    "                        \n",
    "            model = auto.arima(as.ts(trainXts), seasonal=TRUE)\n",
    "            #model = Arima(trainXts, order = c(3, 0, 3), seasonal=list(order=c(3, 0, 3), period = 24))\n",
    "            testXts = trainXts\n",
    "            for (currentPoint in seq(startPoint, endPoint)){\n",
    "                refit = Arima(as.ts(testXts), model=model)\n",
    "                prediction = forecast(refit, h=maxHorizon)$mean\n",
    "                for (h in horizons){\n",
    "                    if (currentPoint+h-1 <= endPoint){\n",
    "                       predictions[[h]][currentPoint+h-1, zone] = predictions[[h]][currentPoint+h-1, zone] + prediction[h]\n",
    "                    }\n",
    "                }            \n",
    "                testXts = c(testXts, xts[currentPoint])\n",
    "            }\n",
    "            \n",
    "            prettyPrint(paste0(\"semiParametric|\", zone, \"|period \", period, \"|Done in \", \n",
    "                               as.numeric(Sys.time()-startTime, units = \"secs\")));\n",
    "        }  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "longTermTrend <- function(E, T, DateTime, BANDWIDTH=12){\n",
    "    E.xts = xts(E, DateTime)\n",
    "    T.xts = xts(T, DateTime)\n",
    "    E.month.xts = apply.monthly(E.xts, FUN=\"mean\", na.rm = TRUE)\n",
    "    I = as.numeric(format(index(E.month.xts), \"%m\"))\n",
    "    #I = quarters (index(E.month.xts), \"%m\")\n",
    "    if (length(I) > 24){\n",
    "        I = factor(I)\n",
    "    }\n",
    "    T = apply.monthly(T.xts[index(E.xts)], FUN=\"mean\", na.rm = TRUE)\n",
    "    E.model = gam(E.month.xts ~ I + s(T))#ERROR!!\n",
    "    E.est = E.model$fitted.values\n",
    "    E.residuals = E.model$residuals\n",
    "    a = NadarayaWatsonkernel(1:length(E.residuals), E.residuals, BANDWIDTH, 1:length(E.residuals))\n",
    "    a$mh\n",
    "    month = as.numeric(format(index(E.xts), \"%m\"))\n",
    "    year = as.numeric(format(index(E.xts), \"%y\"))\n",
    "\n",
    "    idx = (year-year[1])*12+(month-month[1])+1\n",
    "\n",
    "    days = rep(0, length(E.xts))\n",
    "    for (i in 1:length(a$mh)){\n",
    "        days[which(idx == i)]  = sum(idx==i)\n",
    "    }\n",
    "\n",
    "    fraction = as.numeric(format(index(E.xts), \"%d\"))*24 + as.numeric(format(index(E.xts), \"%H\"))\n",
    "\n",
    "    trend.month = c(a$mh[1]-(a$mh[2]-a$mh[1]), a$mh)\n",
    "    trend = rep(0, length(E.xts))\n",
    "    trend = (trend.month[idx+1]-trend.month[idx])*fraction/days + trend.month[idx]\n",
    "    trend.xts = xts(trend, order.by = index(E.xts))\n",
    "    return(drop(coredata(trend.xts)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
